{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:05.953978Z",
     "start_time": "2024-08-06T13:00:01.220360Z"
    }
   },
   "source": [
    "import wandb\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from clap import Clap, ClapAudioClassifier\n",
    "from clap.training import create_scheduler, ClapFinetuner\n",
    "from clap.datasets import ClapDataset\n",
    "from clap.utils import get_target_device, load_clap_config, set_random_seed"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tune ClapAudioClassifier on ESC-50",
   "id": "a0868908e021baa0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:05.961279Z",
     "start_time": "2024-08-06T13:00:05.955481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load config for audio processing and get target device\n",
    "audio_encoder = \"htsat-tiny\"\n",
    "text_encoder = \"gpt2\"\n",
    "cfg_version = 1\n",
    "ckpt_version = 2\n",
    "config = load_clap_config(audio_encoder=audio_encoder, text_encoder=text_encoder, version=cfg_version)\n",
    "device = get_target_device()"
   ],
   "id": "32b1af31280127c4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:06.440853Z",
     "start_time": "2024-08-06T13:00:05.962282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Datasets\n",
    "seed = set_random_seed(None)\n",
    "train_dataset = ClapDataset(config=config, kinds=[\"train\"], datasets=[\"ESC50\"])\n",
    "val_dataset = ClapDataset(config=config, kinds=[\"val\"], datasets=[\"ESC50\"])\n",
    "test_dataset = ClapDataset(config=config, kinds=[\"test\"], datasets=[\"ESC50\"])"
   ],
   "id": "d26cdbcee674bf6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set as 2608568488\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:08.168937Z",
     "start_time": "2024-08-06T13:00:06.442357Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.login()",
   "id": "e7159f0bef2c1e8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mleonakkad\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:11.409434Z",
     "start_time": "2024-08-06T13:00:08.169943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wandb.init(\n",
    "    # Set the wandb project where this run will be logged \n",
    "    project='CLAP-Fine-tuning',\n",
    "    name=\"First fine-tuning run\",\n",
    "    # Track hyperparameters\n",
    "    config=config\n",
    ")\n",
    "config = wandb.config"
   ],
   "id": "f1ff3f240a70e90c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\examples\\wandb\\run-20240806_150008-5ipfh30x</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning/runs/5ipfh30x' target=\"_blank\">First fine-tuning run</a></strong> to <a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning' target=\"_blank\">https://wandb.ai/leonakkad/CLAP-Fine-tuning</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning/runs/5ipfh30x' target=\"_blank\">https://wandb.ai/leonakkad/CLAP-Fine-tuning/runs/5ipfh30x</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:11.415181Z",
     "start_time": "2024-08-06T13:00:11.410943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"fine-tuning\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"fine-tuning\"][\"batch_size\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"fine-tuning\"][\"batch_size\"])"
   ],
   "id": "a31d3c1b931f6e12",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:00:13.311447Z",
     "start_time": "2024-08-06T13:00:11.416189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define model, optimizer, scheduler and loss function\n",
    "clap = Clap.from_ckpt(audio_encoder=audio_encoder, text_encoder=text_encoder, ckpt_version=ckpt_version, cfg_version=cfg_version)\n",
    "clap_clf = ClapAudioClassifier(clap=clap, config=config).to(device)\n",
    "print(f\"Number of parameters to train: {sum(p.numel() for p in clap_clf.parameters())}\")\n",
    "optimizer = optim.Adam(clap.parameters(), lr=config[\"fine-tuning\"][\"learning_rate\"])\n",
    "scheduler = create_scheduler(optimizer, warmup_steps=31, T_max=len(train_loader)*config[\"fine-tuning\"][\"epochs\"], milestones=[31])\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "trainer = ClapFinetuner(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    model=clap_clf,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config[\"fine-tuning\"][\"epochs\"]\n",
    ")"
   ],
   "id": "3a014ceefd66b8e9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leon\\miniconda3\\envs\\custom-clap\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\leon\\miniconda3\\envs\\custom-clap\\Lib\\site-packages\\torch\\functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:3588.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters to train: 158435530\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:02:45.488841Z",
     "start_time": "2024-08-06T13:00:14.128906Z"
    }
   },
   "cell_type": "code",
   "source": "train_metrics, val_metrics, test_metrics = trainer.finetune_and_eval(audio_encoder=audio_encoder, text_encoder=text_encoder, version=1, early_stopping=False)",
   "id": "f39add4ba1ef8ee4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to finetune Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 25/25 [00:30<00:00,  1.22s/it]\n",
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0 || Training loss: 3.8961 || Validation loss: 3.8534 || Training accuracy: 0.1100 || Validation accuracy: 0.4762\n",
      "\n",
      "Model saved to C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\clap\\checkpoints\\clf_htsat-tiny_gpt2_v1.ckpt\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 1:  20%|██        | 5/25 [00:05<00:20,  1.03s/it]C:\\Users\\leon\\miniconda3\\envs\\custom-clap\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Training epoch 1: 100%|██████████| 25/25 [00:25<00:00,  1.01s/it]\n",
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:02<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 || Training loss: 3.7964 || Validation loss: 3.7185 || Training accuracy: 0.6737 || Validation accuracy: 0.8006\n",
      "\n",
      "Model saved to C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\clap\\checkpoints\\clf_htsat-tiny_gpt2_v1.ckpt\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 2: 100%|██████████| 25/25 [00:25<00:00,  1.00s/it]\n",
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:02<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 || Training loss: 3.6738 || Validation loss: 3.6169 || Training accuracy: 0.8594 || Validation accuracy: 0.8405\n",
      "\n",
      "Model saved to C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\clap\\checkpoints\\clf_htsat-tiny_gpt2_v1.ckpt\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 3: 100%|██████████| 25/25 [00:25<00:00,  1.03s/it]\n",
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:02<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3 || Training loss: 3.5926 || Validation loss: 3.5548 || Training accuracy: 0.9038 || Validation accuracy: 0.8812\n",
      "\n",
      "Model saved to C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\clap\\checkpoints\\clf_htsat-tiny_gpt2_v1.ckpt\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 4: 100%|██████████| 25/25 [00:26<00:00,  1.04s/it]\n",
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:02<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4 || Training loss: 3.5517 || Validation loss: 3.5366 || Training accuracy: 0.9313 || Validation accuracy: 0.8769\n",
      "\n",
      "Model saved to C:\\Users\\leon\\Documents\\ML_Projects\\Custom-CLAP\\clap\\checkpoints\\clf_htsat-tiny_gpt2_v1.ckpt\n",
      "\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model on val/test set: 100%|██████████| 4/4 [00:02<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final loss: 3.5365676879882812 || Final test accuracy: 0.8769\n",
      "\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-06T13:24:31.502310Z",
     "start_time": "2024-08-06T13:24:19.597118Z"
    }
   },
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "43417ea49835e5cd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93d4946bf3844cac988db0db22ae6e64"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>test/batch accuracy</td><td>▅▁▇█</td></tr><tr><td>test/batch loss</td><td>▅█▅▁</td></tr><tr><td>test/step</td><td>▁▃▆█</td></tr><tr><td>train/accuracy</td><td>▁▆▇██</td></tr><tr><td>train/batch accuracy</td><td>▁▁▁▁▁▂▂▃▄▅▆▆▆▆▆▆▇▇▇▇█▇▇▇▇▇█▇▇███▇██▇███▇</td></tr><tr><td>train/batch loss</td><td>██████▇▇▇▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>val/accuracy</td><td>▁▇▇██</td></tr><tr><td>val/batch accuracy</td><td>▁▂▂▂▅▆▇▇▇▆▇▇▇▆██▇▆██</td></tr><tr><td>val/batch loss</td><td>████▅▅▅▅▃▃▃▃▂▂▂▁▁▂▁▁</td></tr><tr><td>val/loss</td><td>█▅▃▁▁</td></tr><tr><td>val/step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>test/batch accuracy</td><td>0.91379</td></tr><tr><td>test/batch loss</td><td>3.52291</td></tr><tr><td>test/step</td><td>3</td></tr><tr><td>train/accuracy</td><td>0.93125</td></tr><tr><td>train/batch accuracy</td><td>0.92188</td></tr><tr><td>train/batch loss</td><td>3.5414</td></tr><tr><td>train/loss</td><td>3.55167</td></tr><tr><td>train/step</td><td>124</td></tr><tr><td>val/accuracy</td><td>0.87689</td></tr><tr><td>val/batch accuracy</td><td>0.91379</td></tr><tr><td>val/batch loss</td><td>3.52291</td></tr><tr><td>val/loss</td><td>3.53657</td></tr><tr><td>val/step</td><td>19</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">First fine-tuning run</strong> at: <a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning/runs/5ipfh30x' target=\"_blank\">https://wandb.ai/leonakkad/CLAP-Fine-tuning/runs/5ipfh30x</a><br/> View project at: <a href='https://wandb.ai/leonakkad/CLAP-Fine-tuning' target=\"_blank\">https://wandb.ai/leonakkad/CLAP-Fine-tuning</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240806_150008-5ipfh30x\\logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
