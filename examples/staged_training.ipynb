{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {},
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "from clap import Clap\n",
    "from clap.datasets import ClapDataset\n",
    "from clap.training import ClapTrainer, create_scheduler, SymmetricCrossEntropyLoss\n",
    "from clap.utils import get_target_device, load_clap_config, set_random_seed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stage 1: Train CLAP on audio captioning datasets AudioCaps and ClothoV2",
   "id": "42fa21ffc315fc9a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load config for audio processing and get target device\n",
    "audio_encoder = \"htsat-tiny\"\n",
    "text_encoder = \"gpt2\"\n",
    "cfg_version = \"TestDistillation\"\n",
    "config = load_clap_config(audio_encoder=audio_encoder, text_encoder=text_encoder, version=cfg_version)\n",
    "set_random_seed(config[\"training\"][\"seed\"])\n",
    "device = get_target_device()"
   ],
   "id": "200215a64d7b9d33",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Datasets\n",
    "train_dataset = ClapDataset(config=config, kinds=[\"train\"], datasets=[\"Clotho\"])\n",
    "val_dataset = ClapDataset(config=config, kinds=[\"val\"], datasets=[\"Clotho\"])\n",
    "test_dataset = ClapDataset(config=config, kinds=[\"test\"], datasets=[\"Clotho\"])"
   ],
   "id": "e768d189b841f464",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b8f0357b0121987b",
   "metadata": {},
   "source": [
    "# Use wandb logging (just skip and set enable_wandb_logging to False if not wanted)\n",
    "wandb.login()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f1c5b721f62cd81",
   "metadata": {},
   "source": [
    "wandb.init(\n",
    "    # Set the wandb project where this run will be logged \n",
    "    project='CLAP-Training',\n",
    "    name=\"Stage 1 only on Clotho\",\n",
    "    # Track hyperparameters\n",
    "    config=config\n",
    ")\n",
    "config = wandb.config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9adf38907f6d43cd",
   "metadata": {},
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"training\"][\"batch_size\"])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "clap = Clap(config).to(device)\n",
    "print(f\"Number of parameters to train: {sum(p.numel() for p in clap.parameters())}\")"
   ],
   "id": "afe1a2469daa8e16",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bae277a6c350b548",
   "metadata": {},
   "source": [
    "# Define optimizer, scheduler and loss function\n",
    "optimizer = optim.AdamW(clap.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.999), weight_decay=0)\n",
    "scheduler = create_scheduler(optimizer, warmup_steps=300, T_max=len(train_loader)*config[\"training\"][\"stage1_epochs\"], milestones=[300])\n",
    "loss_fn = SymmetricCrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define trainer\n",
    "stage1_trainer = ClapTrainer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    model=clap,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config[\"training\"][\"stage1_epochs\"],\n",
    "    enable_wandb_logging=True\n",
    ")"
   ],
   "id": "9109d41344f2cc5d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73bc9bffbaf50076",
   "metadata": {},
   "source": "stage1_train_metrics, stage1_val_metrics, stage1_test_metrics = stage1_trainer.train_and_eval(audio_encoder=audio_encoder, text_encoder=text_encoder, version=\"Stage1_Clotho_test\", early_stopping=False)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "2b40a40bc3d0c553",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Stage 2: Continue training by distilling soft-targets from pre-trained CLAP models",
   "id": "b788a734f8eed958"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load config for audio processing and get target device\n",
    "audio_encoder = \"htsat-tiny\"\n",
    "text_encoder = \"gpt2\"\n",
    "cfg_version = \"TestDistillation\"\n",
    "config = load_clap_config(audio_encoder=audio_encoder, text_encoder=text_encoder, version=cfg_version)\n",
    "set_random_seed(config[\"training\"][\"seed\"])\n",
    "device = get_target_device()"
   ],
   "id": "1f677aea0e9bc509",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load Datasets\n",
    "train_dataset = ClapDataset(config=config, kinds=[\"train\"], datasets=[\"Clotho\"])\n",
    "val_dataset = ClapDataset(config=config, kinds=[\"val\"], datasets=[\"Clotho\"])\n",
    "test_dataset = ClapDataset(config=config, kinds=[\"test\"], datasets=[\"Clotho\"])"
   ],
   "id": "277e027e76cdd612",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Use wandb logging (just skip and set enable_wandb_logging to False if not wanted)\n",
    "wandb.login()"
   ],
   "id": "d2bff1d21e02e0eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wandb.init(\n",
    "    # Set the wandb project where this run will be logged \n",
    "    project='CLAP-Training',\n",
    "    name=\"Stage 2 with distillation\",\n",
    "    # Track hyperparameters\n",
    "    config=config\n",
    ")\n",
    "config = wandb.config"
   ],
   "id": "51eb416b15838dbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"training\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"training\"][\"batch_size\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"training\"][\"batch_size\"])"
   ],
   "id": "b02356a6ab10360",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define model\n",
    "clap = Clap.from_ckpt(audio_encoder=audio_encoder, text_encoder=text_encoder, cfg_version=cfg_version, ckpt_version=\"Stage1_Clotho\").to(device)"
   ],
   "id": "6f04a1c1d9b188c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define optimizer, scheduler and loss function\n",
    "optimizer = optim.AdamW(clap.parameters(), lr=config[\"training\"][\"learning_rate\"], betas=(0.9, 0.999), weight_decay=0)\n",
    "scheduler = create_scheduler(optimizer, warmup_steps=300, T_max=len(train_loader)*config[\"training\"][\"stage2_epochs\"], milestones=[300])\n",
    "loss_fn = SymmetricCrossEntropyLoss()"
   ],
   "id": "d5df024b3fbfd6c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define distillation models and loss weight\n",
    "distill_models = []\n",
    "distill_model1 = Clap.from_ckpt(audio_encoder=audio_encoder, text_encoder=text_encoder, cfg_version=cfg_version, ckpt_version=\"Stage1_Clotho\").to(device)\n",
    "distill_model1.freeze_encoders()\n",
    "distill_model1.eval()\n",
    "distill_models.append(distill_model1)\n",
    "\n",
    "distill_from = distill_models\n",
    "distill_weight = 1"
   ],
   "id": "dc6d387e286db169",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stage2_trainer = ClapTrainer(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    test_loader=test_loader,\n",
    "    model=clap,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    loss_fn=loss_fn,\n",
    "    epochs=config[\"training\"][\"stage2_epochs\"],\n",
    "    enable_wandb_logging=True,\n",
    "    distill_from=distill_from,\n",
    "    distill_weight=distill_weight\n",
    ")"
   ],
   "id": "466241a32e7d3283",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stage2_train_metrics, stage2_val_metrics, stage2_test_metrics = stage2_trainer.train_and_eval(audio_encoder=audio_encoder, text_encoder=text_encoder, version=\"Stage2_Distillation_New\", early_stopping=True)",
   "id": "2fd91057337c4a22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wandb.finish()",
   "id": "59979641ecd514f1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
